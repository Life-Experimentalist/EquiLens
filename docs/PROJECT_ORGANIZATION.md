# EquiLens Project Organization

## ğŸ—ï¸ Architecture Overview

EquiLens follows a modular, phase-based architecture designed for systematic bias auditing:

```mermaid
graph TD
    subgraph "ğŸ“ Documentation Layer"
        Docs[ğŸ“š docs/]
        ConfigGuide[ğŸ“– CONFIGURATION_GUIDE.md]
        OrgGuide[ğŸ“‹ PROJECT_ORGANIZATION.md]
        SchemaDoc[ğŸ“„ SCHEMA_SUMMARY.md]
        Examples[ğŸ’¡ example_configurations.json]

        Docs --> ConfigGuide
        Docs --> OrgGuide
        Docs --> SchemaDoc
        Docs --> Examples
    end

    subgraph "ğŸ› ï¸ Tools Layer"
        Tools[ğŸ”§ tools/]
        QuickSetup[âš¡ quick_setup.py]
        Validator[âœ… validate_config.py]

        Tools --> QuickSetup
        Tools --> Validator
    end

    subgraph "ğŸ“Š Phase 1: Configuration & Generation"
        Phase1[ğŸ“ˆ Phase1_CorpusGenerator/]
        Config[âš™ï¸ word_lists.json]
        Schema[ğŸ“‹ word_lists_schema.json]
        Generator[ğŸ­ generate_corpus.py]
        Switcher[ğŸ”„ switch_comparison.py]
        CorpusDir[ğŸ“ corpus/]
        CorpusFiles[ğŸ“„ CSV Files]

        Phase1 --> Config
        Phase1 --> Schema
        Phase1 --> Generator
        Phase1 --> Switcher
        Phase1 --> CorpusDir
        CorpusDir --> CorpusFiles
    end

    subgraph "ğŸ” Phase 2: Model Auditing"
        Phase2[ğŸ”¬ Phase2_ModelAuditor/]
        Auditor[ğŸ•µï¸ audit_model.py]

        Phase2 --> Auditor
    end

    subgraph "ğŸ“ˆ Phase 3: Analysis & Reporting"
        Phase3[ğŸ“Š Phase3_Analysis/]
        Analyzer[ğŸ“‰ analyze_results.py]

        Phase3 --> Analyzer
    end

    subgraph "ğŸ”Œ External Dependencies"
        Ollama[ğŸ¤– Ollama LLM Server]
        Models[ğŸ§  Language Models]

        Ollama --> Models
    end

    %% Data flow connections
    QuickSetup -.->|Creates| Config
    Validator -.->|Validates| Config
    Config -->|Feeds| Generator
    Schema -->|Validates| Config
    Generator -->|Produces| CorpusFiles
    CorpusFiles -->|Input to| Auditor
    Ollama -->|Powers| Auditor
    Auditor -->|Results to| Analyzer

    %% Styling
    style Docs fill:#e3f2fd
    style Tools fill:#f3e5f5
    style Phase1 fill:#e8f5e8
    style Phase2 fill:#fff3e0
    style Phase3 fill:#fce4ec
    style Ollama fill:#ffebee
```

### ğŸ¯ **Architecture Components Explained**

| Layer               | Purpose                    | Key Components                          | Dependencies           |
| ------------------- | -------------------------- | --------------------------------------- | ---------------------- |
| **ğŸ“š Documentation** | User guidance and examples | Configuration guides, schemas, examples | None                   |
| **ğŸ› ï¸ Tools**         | Interactive utilities      | Setup wizard, configuration validator   | Documentation layer    |
| **ğŸ“Š Phase 1**       | Bias test generation       | Configuration files, corpus generator   | Tools layer            |
| **ğŸ” Phase 2**       | Model testing              | Audit scripts, bias measurement         | Phase 1 output, Ollama |
| **ğŸ“ˆ Phase 3**       | Results analysis           | Statistical analysis, reporting         | Phase 2 output         |
| **ğŸ”Œ External**      | Language model services    | Ollama server, model instances          | Independent            |

## ğŸŒŠ Data Flow Pipeline

The EquiLens framework processes bias testing through a systematic data pipeline:

```mermaid
flowchart LR
    subgraph "ğŸ“¥ Input Stage"
        UserReq[ğŸ‘¤ User Requirements<br/>Define bias type to test]
        ConfigStart[âš™ï¸ Configuration Creation<br/>Manual or interactive]
    end

    subgraph "ğŸ”§ Configuration Processing"
        JSON[ğŸ“„ word_lists.json<br/>Bias configuration]
        Validation[âœ… Schema Validation<br/>Ensure compliance]
        Switch[ğŸ”„ Type Selection<br/>Activate specific bias test]
    end

    subgraph "ğŸ­ Corpus Generation"
        Generator[âš™ï¸ generate_corpus.py<br/>Systematic combination]
        CSV[ğŸ“Š audit_corpus_*.csv<br/>Test sentences with metadata]
        Stats[ğŸ“ˆ Statistics<br/>Combination counts]
    end

    subgraph "ğŸ¤– Model Interaction"
        LLM[ğŸ§  Language Model<br/>via Ollama API]
        Audit[ğŸ” audit_model.py<br/>Bias measurement]
        Responses[ğŸ’¬ Model Responses<br/>with surprisal scores]
    end

    subgraph "ğŸ“Š Analysis & Output"
        Analysis[ğŸ“‰ analyze_results.py<br/>Statistical processing]
        Reports[ğŸ“‹ Bias Reports<br/>Findings and visualizations]
        Insights[ğŸ’¡ Actionable Insights<br/>Bias patterns identified]
    end

    UserReq --> ConfigStart
    ConfigStart --> JSON
    JSON --> Validation
    Validation --> Switch
    Switch --> Generator
    Generator --> CSV
    Generator --> Stats
    CSV --> Audit
    LLM --> Audit
    Audit --> Responses
    Responses --> Analysis
    Analysis --> Reports
    Reports --> Insights

    style UserReq fill:#e3f2fd
    style JSON fill:#f3e5f5
    style CSV fill:#e8f5e8
    style LLM fill:#fff3e0
    style Reports fill:#fce4ec
    style Insights fill:#e8eaf6
```

### ğŸ“‹ **Pipeline Stages Explained**

| Stage               | Input             | Process                     | Output                   | Key Metrics         |
| ------------------- | ----------------- | --------------------------- | ------------------------ | ------------------- |
| **ğŸ“¥ Input**         | User requirements | Bias type definition        | Configuration parameters | Scope definition    |
| **ğŸ”§ Configuration** | Parameters        | JSON creation & validation  | Valid configuration      | Schema compliance   |
| **ğŸ­ Generation**    | Configuration     | Systematic combinations     | Test corpus (CSV)        | Combination count   |
| **ğŸ¤– Model Testing** | Test corpus       | API calls to language model | Response data            | Surprisal scores    |
| **ğŸ“Š Analysis**      | Response data     | Statistical processing      | Bias reports             | Significance levels |

### **ğŸ¯ Data Transformation Examples:**

1. **Configuration â†’ Corpus:**
   ```
   "John" + "engineer" + "analytical" + template
   â†’ "John, the engineer, is known for being very analytical."
   ```

2. **Corpus â†’ Model Response:**
   ```
   Test sentence â†’ Ollama API â†’ Response time & content â†’ Surprisal score
   ```

3. **Responses â†’ Insights:**
   ```
   Multiple surprisal scores â†’ Statistical comparison â†’ Bias measurement
   ```

## ğŸ—‚ï¸ Clean File Structure

```
workspace/
â”œâ”€â”€ ğŸ“ docs/                           # Documentation & Examples
â”‚   â”œâ”€â”€ CONFIGURATION_GUIDE.md         # Detailed setup guide
â”‚   â”œâ”€â”€ PROJECT_ORGANIZATION.md        # This file
â”‚   â”œâ”€â”€ SCHEMA_SUMMARY.md              # Complete tool overview
â”‚   â”œâ”€â”€ example_configurations.json    # Pre-built bias type examples
â”‚   â””â”€â”€ ppt.md                         # Project presentation notes
â”‚
â”œâ”€â”€ ğŸ“ tools/                          # Utility Scripts
â”‚   â”œâ”€â”€ validate_config.py             # Configuration validator
â”‚   â””â”€â”€ quick_setup.py                 # Interactive config creator
â”‚
â”œâ”€â”€ ğŸ“ Phase1_CorpusGenerator/         # Corpus Generation
â”‚   â”œâ”€â”€ word_lists.json                # Main configuration file
â”‚   â”œâ”€â”€ word_lists_schema.json         # JSON Schema (same location as config)
â”‚   â”œâ”€â”€ generate_corpus.py             # Corpus generator
â”‚   â”œâ”€â”€ switch_comparison.py           # Comparison switcher
â”‚   â””â”€â”€ ğŸ“ corpus/                     # Generated corpus files
â”‚       â”œâ”€â”€ audit_corpus_gender_bias.csv
â”‚       â”œâ”€â”€ audit_corpus_nationality_bias.csv
â”‚       â””â”€â”€ audit_corpus_cross_cultural_gender.csv
â”‚
â”œâ”€â”€ ğŸ“ Phase2_ModelAuditor/            # Model Testing
â”‚   â””â”€â”€ audit_model.py                 # Model bias auditing
â”‚
â”œâ”€â”€ ğŸ“ Phase3_Analysis/                # Results Analysis
â”‚   â””â”€â”€ analyze_results.py             # Bias analysis & visualization
â”‚
â”œâ”€â”€ ğŸ“ .devcontainer/                  # Development Environment
â”‚   â”œâ”€â”€ devcontainer.json
â”‚   â””â”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ README.md                          # Main documentation
â””â”€â”€ requirements.txt                   # Python dependencies
```

## ğŸ¯ Key Organizational Principles

### 1. **Clean Root Directory**
- Only essential files at the root level
- README.md and requirements.txt are the only files developers need immediately
- No scattered configuration or utility files

### 2. **Schema Co-location**
- `word_lists_schema.json` is in the same directory as `word_lists.json`
- This makes it easy to find and maintain the schema alongside the configuration
- Validation tools automatically find the schema in the expected location

### 3. **Documentation Separation**
- All documentation (except README) is in `docs/` directory
- Presentation materials, guides, and examples are properly organized
- Easy to find and maintain documentation

### 4. **Tool Isolation**
- Interactive and utility scripts are in `tools/` directory
- These are NOT executed during Docker builds
- They are developer tools for creating and validating configurations

## ğŸ”§ Tool Usage (Not Auto-Executed)

The tools in the `tools/` directory are **developer utilities** and are **not** executed automatically:

### `tools/quick_setup.py`
- **Purpose**: Interactive configuration creator for developers
- **When to use**: When you want to create a new bias comparison type
- **Execution**: Manual only - `python tools/quick_setup.py`
- **Docker**: Not executed during Docker build

### `tools/validate_config.py`
- **Purpose**: Validate configuration files before use
- **When to use**: Before generating corpus or when debugging configuration issues
- **Execution**: Manual only - `python tools/validate_config.py`
- **Docker**: Not executed during Docker build

## ğŸ³ Docker Build Process

The Docker container setup (`.devcontainer/`) only:
1. Sets up Python environment
2. Installs packages from `requirements.txt`
3. Configures Ollama service
4. **Does NOT run any tools automatically**

## ğŸ“ Usage Workflow

### For New Users:
```bash
# 1. Create configuration (optional - defaults exist)
python tools/quick_setup.py

# 2. Validate configuration
python tools/validate_config.py

# 3. Generate corpus
cd Phase1_CorpusGenerator
python generate_corpus.py
```

### For Existing Configurations:
```bash
# Just generate and use
cd Phase1_CorpusGenerator
python generate_corpus.py
```

## ğŸ‰ Benefits of This Organization

1. **Clean Root**: Only essential files visible at first glance
2. **Logical Grouping**: Related files are together
3. **No Confusion**: Clear separation between docs, tools, and phases
4. **Schema Co-location**: Configuration and schema are together
5. **Professional**: Follows standard open-source project structure
6. **Docker-Safe**: No unexpected tool execution during builds
